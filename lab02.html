<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evaluation | Graham Gobbel</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="lab02.html" class="active">Lab 2: AI Evaluation</a>
            <!-- Add more lab links as the semester progresses -->
        </nav>
        <h1>AI Tool Evaluation</h1>
    </header>

    <main>
        <section>
            <h2>Introduction</h2>
            <p>I chose to explore two different generative AI tools, ChatGPT and LeonardoAI.
                Both tools have gained significant popularity recently and offer unique capabilities in their respective domains.
                One of them, ChatGPT, I use almost every day, and the other, LeonardoAI, I have not used until now. 
                In this evaluation, I will discuss the capabilities, appropriate use cases, and ethical considerations for each tool,
                along with examples of how I have used them in my own work.
            </p>
        </section>

        <section>
            <h2>Tool 1: ChatGPT</h2>
            <h3>Capabilities</h3>
            <p> ChatGPT is a go-to generative AI tool for a large part of the population
                because of its wide range of capabilites and general reliability. Some of its biggest pros
                are its ability to generate human-like text, assist with brainstorming, provide explanations,
                and even write code. For students, ChatGPT can help with drafting essays, summarizing articles,
                and answering questions on a variety of topics. For business professionals, it can assist in creating reports,
                drafting emails, and generating content ideas. And for the general user, ChatGPT can be a helpful tool for learning 
                new information, getting recommendations, and even just having casual conversations. 
                However, although ChatGPT is powerful and has many strengths, it also has its limitations. First and foremost,
                it is nearly impossible for ChatGPT to promise 100% accuracy, as it can sometimes produce incorrect or misleading information.
                On top of that, ChatGPT may even sound confident in its responses, even when it is wrong. Additionally, ChatGPT's
                knowledge is limited to information available up until its last training cut-off date, which means it may not be aware 
                of the most recent events or developments. Finally, while ChatGPT can generate text that appears human-like, 
                it lacks true understanding and context, which can lead to responses. In conclusion, ChatGPT is a powerful tool with a
                wide range of capabilities, however it is important for users to always fact-check and never fully rely on it for critical information.</p>

            <h3>Appropriate Use</h3>
            <p>Good use cases of ChatGPT include brainstorming ideas, drafting & editing, summarizing information, and structured problem solving.
                On the other hand, poor use cases include relying on it for final authority on factual or legal matters, creating original creative work,
                using it for domain-specific expertise without verification, and engaging in unethical activities such as plagiarism or generating harmful content.
                

             <figure>
                <img src="images/ChatExLab2.png" alt="Screenshot of ChatGPT troubleshooting HTML code" width="100%">

                <figcaption>In the image above, you can see an example of how I used ChatGPT to help me troubleshoot a coding issue I was having in HTML. I described the problem
                very generally, and ChatGPT was able to provide me with 7 different potential solutions to try out. This helped me quickly identify and fix the issue I was having.</figcaption>
            </figure>
               
            </p>

            <h3>Ethical Considerations</h3>
            <p>While its easy for users to go blind to ethical concerns ChatGPT may raise, it's important to remember that they are still there.
                These concerns range all the way from data privacy to bias used in its repsonses. First, users should be cautious about sharing sensitive or 
                personal information with ChatGPT, as the data inputted may be stored and used for further training of the model. Next, ChatGPT can sometimes 
                produce biased or unfair responses based on the data it was trained on, which can lead to stereotypes of discrimination. Concerns such as these
                are continuing to be addressed through tranining methods developers are using in the hopes to reduce bias through built-in content restrictions,
                and reminders for users to fact-check information provided by the AI. However, there is only so much safe-guards can do. Ethical use of ChatGPT still
                depends on how responsibly its users apply the tools and whether it is ised to support thinking rather than replace it.
            </p>

            <!-- Add screenshots or examples -->
           
        </section>

        <section>
            <h2>Tool 2: Leonardo AI</h2>
            <h3>Capabilities</h3>
            <p>Leonardo AI is an image generation tool that uses artificial intelligence to create detailed and creative images based on user prompts.
                It is known for its ability to create high-quality images with a focus on artistic styles while also being user and beginner friendly.
                Users can input text descriptions, and Leonardo AI will generate images that match the given prompts. This makes it a powerful tool for artists,
                designers, and content creators looking to visualize concepts quickly. It is able to produce the images quickly, usually within a minute, while keeping
                the images high-quality. However, like many AI image generators, Leonardo AI has its limitations. The quality of the generated images can vary 
                based on the complexity of the prompt and the training data the model has been exposed to. Sometimes, the image that is produced may not fully align
                with what the user hoped for or stated in their prompt. This may look like spelling errors, odd details in the image, or elements that seem out of place.
                One of the hardest things is generating realistic objects which may take multiple attempts to get right;
            <h3>Appropriate Use</h3>
            <p>Good use cases include creating concept art, visualizing ideas quickly, and generating artistic images for inspiration or projects.
                Poor use cases include relying on it for highly detailed or specific imagery, using it for commercial purposes without proper rights,
                and generating images that may infringe on copyrights or intellectual property. </p>
                 
            <h3>Ethical Considerations</h3>
            <p>One of the biggest ethical concerns for an image generating AI like Leonardo AI is copyright and artist attribution.
                What this means is that this tool is trained on styles and work from real artists, possibly without their consent,
                and sometimes the images that Leonardo AI generates can closely resemble that work. This raises a lot of concerns about 
                creatve ownership and property rights. To address these concerns, Leonardo AI implements restrictions on prompts that 
                reference spefific artits and attempts to prevent direct copying of styles. However, it is still important for users 
                to be aware of these issues as they are still not coompletely resolved. Also, users should be cautious about generating 
                images that may be offensive or harmful, as the AI may inadvertently produce content that is inappropriate. At the end of 
                the day, similar to what I mentioned in regards to ChatGPT, ethical use of Leonardo AI depends on how responsibly its users 
                apply the tool. 
            </p>
            
            <figure>
               <img src="images/LeoAILab2.jpg" alt="Example image generated by Leonardo AI based on a complex prompt" width="100%">
               
               <figcaption>In the image above, you can see how Leonardo AI brought
                my abstract prompt of " a college girl and her five roommates in Texas Christian University merchandise at a football game,
                 but the football field is in the middle of an ocean, and there is a pack of rainbow dolphins jumping out of the water" to life.
                 It did a decent job for the first try, but you can see some of the limitations I mentioned earlier with the odd details in the image, 
                 such as spelling errors, the placement of the girls in the water, and the innacurate proportions of everything.
            </p></figcaption>
            </figure>
        </section>

        <section>
            <h2>Broader Reflections</h2>
            <p>I see AI tools as something that should support my thinking, not replace it, especially when critical thinking is becoming more and more of a valued skill in the job market. In my academic work, I already use AI in practical ways, 
                like helping me understand coding errors, walking through accounting problems step by step, or clarifying technical concepts in my cybersecurity class
                labs when instructions feel new and overwhelming. It’s especially helpful when I’m stuck and need something explained differently, but the learning still 
                happens because I’m applying it myself afterward. For writing and presentations, AI is most useful for organizing ideas, tightening wording, or helping me see where 
                something is unclear, rather than producing final content for me.
                <p>In the DCDA context, AI tools can be really valuable for working with data and digital systems more efficiently. For example, tools that help explain data trends,
                 debug code, or summarize technical information can free up time to focus on interpretation and meaning. At the same time, there’s a risk that students could rely on 
                 AI to skip the harder parts of learning, like struggling through problem-solving. I used to view failure as bad thing and something to try my best to avoid, but that
                is one of the biggest things that has proved to be false in my time at college, especially in the field I am in. When learning new skills, like coding,
                trying, failing, and trying again is the most beneficial way to master that new skill, even though it may be frustrating. Although it can be so tempting to take the easy way
                out and let an AI tool do the thinking for you, and even I can be guilty of this at times, it is so important to remember to keep trying and learning on your own.</p>

                <p>Because AI tools are changing so quickly, it’s important to evaluate them carefully before using them, and I think this is a step that a lot of people forget about. When I look at a new AI tool, I 
                 now know to examine how accurate it is,
                 where its limitations are, how it handles data and privacy, and whether it actually helps me learn or just gives fast answers. Based on my experience, the most useful tools 
                 are the ones that push me to think more clearly rather than think less.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2026 Graham Gobbel | <a href="https://github.com/yourusername/dcda-portfolio">GitHub</a></p>
    </footer>
</body>
</html>